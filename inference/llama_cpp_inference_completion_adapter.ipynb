{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Llama.cpp python inference\n",
    "https://llama-cpp-python.readthedocs.io/en/latest/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inference over our trained ascii adapters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_cpp import Llama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "llama_init_from_model: n_ctx_per_seq (416) < n_ctx_train (131072) -- the full capacity of the model will not be utilized\n",
      "ggml_metal_init: skipping kernel_get_rows_bf16                     (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_1row              (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_f32_l4                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_bf16_bf16                  (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mv_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_bf16_f32                   (not supported)\n",
      "ggml_metal_init: skipping kernel_mul_mm_id_bf16_f32                (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h64           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h80           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h96           (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h112          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h128          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_bf16_h256          (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h128      (not supported)\n",
      "ggml_metal_init: skipping kernel_flash_attn_ext_vec_bf16_h256      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_f32_bf16                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_f32                      (not supported)\n",
      "ggml_metal_init: skipping kernel_cpy_bf16_bf16                     (not supported)\n"
     ]
    }
   ],
   "source": [
    "# local paths to the gguf base model and the lora adapter for generating ascii art\n",
    "# get ascii art lora gguf from\n",
    "# get llama 3.2 base gguf from \n",
    "# store them locally and point to them here\n",
    "lora_path = \"update the path\"\n",
    "base_model_path = \"update the path\"\n",
    "\n",
    "\n",
    "llm = Llama(model_path=base_model_path, lora_path=lora_path, verbose=False, n_ctx=400)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_ascii_art(max_tokens: int, generation_config) -> str:\n",
    "    prompt = \"\"\n",
    "    for chunk in llm.create_completion(\n",
    "        prompt, \n",
    "        max_tokens=max_tokens, \n",
    "        stream=True, \n",
    "        temperature=generation_config[\"temperature\"], \n",
    "        top_p=generation_config[\"top_p\"], \n",
    "        min_p=generation_config[\"min_p\"], \n",
    "        frequency_penalty=generation_config[\"frequency_penalty\"], \n",
    "        presence_penalty=generation_config[\"presence_penalty\"], \n",
    "        repeat_penalty=generation_config[\"repeat_penalty\"], \n",
    "        top_k=generation_config[\"top_k\"]\n",
    "    ):\n",
    "        chunk_text = chunk[\"choices\"][0][\"text\"]\n",
    "        print(chunk_text, end=\"\", flush=True)        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nucleus sampling https://arxiv.org/pdf/1904.09751\n",
    "default_generation_config = {\n",
    "    # Higher values are more random. OpenAI recommmends either using temperature or top_p, but not both No effect if temperature is set to 1\n",
    "    \"temperature\" : 0.5,\n",
    "    # Model only considers the smallest set of most probable tokens whose cumulative probability exceeds top_p. No effect if top_p is set to 1\n",
    "    \"top_p\" : 1,\n",
    "    # Minimum probability required to sample a token\n",
    "    \"min_p\" : 0,\n",
    "    # Positive values penalize new tokens based on their existing frequency in the text so far\n",
    "    \"frequency_penalty\" : 0.0,\n",
    "    # Positive values penalize new tokens based on whether they appear in the text so far.\n",
    "    \"presence_penalty\" : 0.0,\n",
    "    # The penalty to apply to repeated tokens\n",
    "    \"repeat_penalty\" : 1,\n",
    "    # Only consider top_k highest probability tokens for each step\n",
    "    \"top_k\" : 50,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation config:  {'temperature': 0.2, 'top_p': 1, 'min_p': 0, 'frequency_penalty': 0.0, 'presence_penalty': 0.0, 'repeat_penalty': 1, 'top_k': 50}\n",
      "Generating ascii art 1 of 50\n",
      "\n",
      "\n",
      "  |\\__/,|   (`\\\n",
      "  |_ _  |.-'  ) )\n",
      "  ( T   )  _  /\n",
      " (((^_(((/(((_>\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 2 of 50\n",
      "\n",
      "\n",
      "  |\\__/,|   (`\\\n",
      "  |_ _  |.-'  ) )\n",
      "  ( T   )  _  /\n",
      " (((^_(((/(((_>\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 3 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 4 of 50\n",
      "\n",
      "\n",
      "  |\\__/,|   (`\\\n",
      "  |_ _  |.-'  .-'\n",
      "  ( T   )  >#<  \\\n",
      "  `.  ;.'  /   \\  \\\n",
      "  | | | | /     \\  \\\n",
      "  \\_`_`_/  `-----'  /\n",
      "  ( `--'   (       )\n",
      "   )_-)    \\__)    \\\n",
      "   '.\\    /  `--'  /\n",
      "   )_).  /       \\  \\\n",
      "  (___/  (_______) /\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 5 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 6 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 7 of 50\n",
      "\n",
      "\n",
      "  |\\__/,|   (`\\\n",
      "  |_ _  |.-'  ) )\n",
      "  ( T   )  _  /\n",
      " (((^_(((/(((_>\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 8 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 9 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( T.T ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 10 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 11 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( T.T ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 12 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 13 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 14 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 15 of 50\n",
      "\n",
      "\n",
      "  /\\ ___ /\\\n",
      " (  >   <  )\n",
      "  \\  >#<  /\n",
      "  /       \\\n",
      " /         \\\n",
      " |         |\n",
      "  \\       /\n",
      "  /// /// --\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 16 of 50\n",
      "\n",
      "\n",
      "  |\\__/,|   (`\\\n",
      "  |o o  |__ _) )\n",
      "_  T  _/  `  /\n",
      "((_ `--.  /_<  \\\n",
      " `` `-'(((/  (((/\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 17 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 18 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 19 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 20 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 21 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^-^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 22 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 23 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 24 of 50\n",
      "\n",
      "\n",
      "  |\\__/,|   (`\\\n",
      "  |_ _  |.-'  ) )\n",
      "  ( T   )  _  /\n",
      " (((^_(((/(((_>\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 25 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 26 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 27 of 50\n",
      "\n",
      "\n",
      "  |\\__/,|   (`\\\n",
      "  |_ _  |.-'  ) )\n",
      "  ( T   )  _  /\n",
      " (((^_(((/(((_>\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 28 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 29 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 30 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 31 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/  (\n",
      " ( | | )\n",
      "(__d b__)\n",
      "\n",
      "\n",
      "\n",
      "Generating ascii art 32 of 50\n",
      "\n",
      "\n",
      "  /\\_/\\  (\n",
      " ( ^.^ ) _)\n",
      "   \\\"/"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 5\u001b[39m\n\u001b[32m      3\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[32m100\u001b[39m):\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mGenerating ascii art \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi+\u001b[32m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m of 50\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m5\u001b[39m     \u001b[43mgenerate_ascii_art\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m200\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdefault_generation_config\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[3]\u001b[39m\u001b[32m, line 3\u001b[39m, in \u001b[36mgenerate_ascii_art\u001b[39m\u001b[34m(max_tokens, generation_config)\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mgenerate_ascii_art\u001b[39m(max_tokens: \u001b[38;5;28mint\u001b[39m, generation_config) -> \u001b[38;5;28mstr\u001b[39m:\n\u001b[32m      2\u001b[39m     prompt = \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mllm\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcreate_completion\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[43m        \u001b[49m\u001b[43mprompt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      5\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      6\u001b[39m \u001b[43m        \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      7\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtemperature\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      8\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m      9\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mmin_p\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     10\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mfrequency_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     11\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mpresence_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     12\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mrepeat_penalty\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\n\u001b[32m     13\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgeneration_config\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtop_k\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     14\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     15\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunk_text\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mchoices\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mtext\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m     16\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mprint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mchunk_text\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mend\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mflush\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/programming/llm-finetuning-resources/.venv/lib/python3.12/site-packages/llama_cpp/llama.py:1320\u001b[39m, in \u001b[36mLlama._create_completion\u001b[39m\u001b[34m(self, prompt, suffix, max_tokens, temperature, top_p, min_p, typical_p, logprobs, echo, stop, frequency_penalty, presence_penalty, repeat_penalty, top_k, stream, seed, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, model, stopping_criteria, logits_processor, grammar, logit_bias)\u001b[39m\n\u001b[32m   1318\u001b[39m finish_reason = \u001b[33m\"\u001b[39m\u001b[33mlength\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1319\u001b[39m multibyte_fix = \u001b[32m0\u001b[39m\n\u001b[32m-> \u001b[39m\u001b[32m1320\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1321\u001b[39m \u001b[43m    \u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1322\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_k\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1323\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtop_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1324\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmin_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1325\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtypical_p\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1326\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtemp\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemperature\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1327\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtfs_z\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1328\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1329\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_tau\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1330\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmirostat_eta\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1331\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrequency_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1332\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpresence_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1333\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepeat_penalty\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1334\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstopping_criteria\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1335\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlogits_processor\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1336\u001b[39m \u001b[43m    \u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m=\u001b[49m\u001b[43mgrammar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1337\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1338\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mllama_cpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mllama_token_is_eog\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_model\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvocab\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1339\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtext\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetokenize\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcompletion_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mprev_tokens\u001b[49m\u001b[43m=\u001b[49m\u001b[43mprompt_tokens\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/programming/llm-finetuning-resources/.venv/lib/python3.12/site-packages/llama_cpp/llama.py:912\u001b[39m, in \u001b[36mLlama.generate\u001b[39m\u001b[34m(self, tokens, top_k, top_p, min_p, typical_p, temp, repeat_penalty, reset, frequency_penalty, presence_penalty, tfs_z, mirostat_mode, mirostat_tau, mirostat_eta, penalize_nl, logits_processor, stopping_criteria, grammar)\u001b[39m\n\u001b[32m    910\u001b[39m \u001b[38;5;66;03m# Eval and sample\u001b[39;00m\n\u001b[32m    911\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m912\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43meval\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    913\u001b[39m     \u001b[38;5;28;01mwhile\u001b[39;00m sample_idx < \u001b[38;5;28mself\u001b[39m.n_tokens:\n\u001b[32m    914\u001b[39m         token = \u001b[38;5;28mself\u001b[39m.sample(\n\u001b[32m    915\u001b[39m             top_k=top_k,\n\u001b[32m    916\u001b[39m             top_p=top_p,\n\u001b[32m   (...)\u001b[39m\u001b[32m    930\u001b[39m             idx=sample_idx,\n\u001b[32m    931\u001b[39m         )\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/programming/llm-finetuning-resources/.venv/lib/python3.12/site-packages/llama_cpp/llama.py:646\u001b[39m, in \u001b[36mLlama.eval\u001b[39m\u001b[34m(self, tokens)\u001b[39m\n\u001b[32m    642\u001b[39m n_tokens = \u001b[38;5;28mlen\u001b[39m(batch)\n\u001b[32m    643\u001b[39m \u001b[38;5;28mself\u001b[39m._batch.set_batch(\n\u001b[32m    644\u001b[39m     batch=batch, n_past=n_past, logits_all=\u001b[38;5;28mself\u001b[39m.context_params.logits_all\n\u001b[32m    645\u001b[39m )\n\u001b[32m--> \u001b[39m\u001b[32m646\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_ctx\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdecode\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_batch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    647\u001b[39m \u001b[38;5;66;03m# Save tokens\u001b[39;00m\n\u001b[32m    648\u001b[39m \u001b[38;5;28mself\u001b[39m.input_ids[n_past : n_past + n_tokens] = batch\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Documents/programming/llm-finetuning-resources/.venv/lib/python3.12/site-packages/llama_cpp/_internals.py:306\u001b[39m, in \u001b[36mLlamaContext.decode\u001b[39m\u001b[34m(self, batch)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdecode\u001b[39m(\u001b[38;5;28mself\u001b[39m, batch: LlamaBatch):\n\u001b[32m--> \u001b[39m\u001b[32m306\u001b[39m     return_code = \u001b[43mllama_cpp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mllama_decode\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    307\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mctx\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    308\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbatch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    309\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m return_code != \u001b[32m0\u001b[39m:\n\u001b[32m    311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mllama_decode returned \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mreturn_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "print(\"Generation config: \", default_generation_config)\n",
    "\n",
    "for i in range(100):\n",
    "    print(f\"Generating ascii art {i+1} of 50\\n\")\n",
    "    generate_ascii_art(max_tokens=200, generation_config=default_generation_config)\n",
    "    print(\"\\n\\n\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
